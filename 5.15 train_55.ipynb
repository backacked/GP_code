{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27bd65ea-bf9d-45db-839c-a84df83911e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over1\n",
      "over2\n",
      "Python       : 3.8.20 (default, Oct  3 2024, 15:19:54) [MSC v.1929 64 bit (AMD64)]\n",
      "Numpy        : 1.23.5\n",
      "Skimage      : 0.20.0\n",
      "Scikit-learn : 1.1.3\n",
      "Keras        : 2.4.0\n",
      "Tensorflow   : 2.3.0\n"
     ]
    }
   ],
   "source": [
    "#这个文件用于训练一个标准的双任务5分类segnet语义分割网络\n",
    "img_height, img_width = (256,256)# 输入图像尺寸\n",
    "out_channel = 5# 输出频道数\n",
    "\n",
    "print('over1')\n",
    "\n",
    "# 导入必要的库\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import sys\n",
    "import shutil\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "print('over2')\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D, UpSampling2D, Reshape\n",
    "from tensorflow.keras.layers import MaxPooling2D, Permute\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "\n",
    "# 打印环境版本信息\n",
    "print('Python       :', sys.version.split('\\n')[0])\n",
    "print('Numpy        :', np.__version__)\n",
    "print('Skimage      :', skimage.__version__)\n",
    "print('Scikit-learn :', sklearn.__version__)\n",
    "print('Keras        :', keras.__version__)\n",
    "print('Tensorflow   :', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f4e812-90d2-4cf5-b0c2-33db0153d6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子保证可重复性，使生成器对准\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed(seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3949ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "项目文件夹路径: C:\\\n",
      "代码文件夹路径: C:\\GP_code\n",
      "图片文件夹路径: C:\\GP_img\n",
      "权重文件夹路径: C:\\GP_wei\n",
      "over\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "topDir = os.path.dirname(os.path.abspath(__file__))# 动态获取当前脚本的父目录\n",
    "__file__是Python内置变量，表示当前脚本的绝对路径。但在交互式环境中，没有\"当前脚本\"的概念，因此该变量不存在\n",
    "如果代码保存为.py文件并直接执行，__file__可以正常使用，但需添加路径修正逻辑\n",
    "'''\n",
    "codDir = os.getcwd()#获取代码所在文件夹\n",
    "topDir = os.path.dirname(codDir)#获取代码所在文件夹的上一级文件夹\n",
    "print('项目文件夹路径:',topDir)\n",
    "codDir = os.path.join(topDir, \"GP_code\")\n",
    "print('代码文件夹路径:',codDir)\n",
    "imgDir = os.path.join(topDir, \"GP_img\")# 获取图片所在文件夹\n",
    "print('图片文件夹路径:',imgDir)\n",
    "weiDir = os.path.join(topDir, \"GP_wei\")# 获取权重所在文件夹\n",
    "print('权重文件夹路径:',weiDir)\n",
    "nor5Dir = os.path.join(topDir, \"nor5\")\n",
    "aug5Dir = os.path.join(topDir, \"aug5\")\n",
    "aug55Dir = os.path.join(topDir, \"aug55\")\n",
    "aug2Dir = os.path.join(topDir, \"aug2\")\n",
    "aug25Dir = os.path.join(topDir, \"aug25\")\n",
    "\n",
    "weiPre = \"model-weights_pre.hdf5\"#预训练权重名称\n",
    "weiDur = \"model-weights_dur.hdf5\"#训练中权重名称\n",
    "weiEnd = \"model-weights_end.hdf5\"#训练后权重名称\n",
    "\n",
    "#preDir = os.path.join(aug55Dir, weiPre)# 预训练权重保存目录\n",
    "#workDir = os.path.join(aug55Dir, weiDur)# 权重动态保存目录\n",
    "#endDIr = os.path.join(aug55Dir, weiEnd)# 训练结束权重保存目录\n",
    "\n",
    "os.chdir(topDir)#不要重复运行该框\n",
    "print('over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59b94056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型结构\n",
    "\"\"\"\n",
    "定义函数keras_model\n",
    "输入图片尺寸(img_width=256, img_height=256, out_channel)\n",
    "输出一个模型model\n",
    "\"\"\"\n",
    "def keras_model(img_width=256, img_height=256, out_channel=out_channel):\n",
    "    \"\"\"\n",
    "    构建多任务深度学习模型\n",
    "    输入尺寸: (256, 256, 3)\n",
    "    输出:\n",
    "    - 分割结果: (256, 256, 1) 经过softmax激活\n",
    "    - 分类结果: (4,) 四类概率分布\n",
    "    结构特点:\n",
    "    - 编码器使用VGG风格的卷积块\n",
    "    - 解码器使用转置卷积进行上采样\n",
    "    - 多任务输出：分割+分类\n",
    "    \"\"\"\n",
    "    # 输入层配置匹配\n",
    "    \"\"\"\n",
    "    K.image_data_format()获得输入图片格式\n",
    "    \"\"\"\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        ch_axis = 1\n",
    "        input_shape = (3, img_height, img_width)\n",
    "    elif K.image_data_format() == 'channels_last':\n",
    "        ch_axis = 3\n",
    "        input_shape = (img_height, img_width, 3)\n",
    "    \n",
    "    inp = Input(shape=input_shape)\n",
    "\n",
    "    # encoder\n",
    "    enc = inp\n",
    "    enc = Conv2D(64, (3, 3), strides=(1, 1), input_shape=input_shape, padding='same', activation='relu')(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu')(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = MaxPooling2D(pool_size=(2, 2))(enc)# 长宽减半\n",
    "    # (128,128)\n",
    "    enc = Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu')(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu')(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = MaxPooling2D(pool_size=(2, 2))(enc)# 长宽减半\n",
    "    # (64,64)\n",
    "    enc = Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu')(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu')(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu')(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = MaxPooling2D(pool_size=(2, 2))(enc)# 长宽减半\n",
    "    # (32,32)\n",
    "    enc = Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu')(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu')(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu')(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = MaxPooling2D(pool_size=(2, 2))(enc)# 长宽减半\n",
    "    # (16,16)\n",
    "    enc = Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu')(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu')(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu')(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = MaxPooling2D(pool_size=(2, 2))(enc)# 长宽减半\n",
    "    # (8,8)\n",
    "    # decoder\n",
    "    dec0 = UpSampling2D(size=(2, 2))(enc)# 长宽加倍\n",
    "    # (16,16)\n",
    "    dec = Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu')(dec0)\n",
    "    dec = BatchNormalization()(dec)\n",
    "    dec = Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu')(dec)\n",
    "    dec = BatchNormalization()(dec)\n",
    "    dec = Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu')(dec)\n",
    "    dec = BatchNormalization()(dec)\n",
    "    dec = UpSampling2D(size=(2, 2))(dec)# 长宽加倍\n",
    "    # (32,32)\n",
    "    dec = Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu')(dec)\n",
    "    dec = BatchNormalization()(dec)\n",
    "    dec = Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu')(dec)\n",
    "    dec = BatchNormalization()(dec)\n",
    "    dec = Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu')(dec)\n",
    "    dec = BatchNormalization()(dec)\n",
    "    dec = UpSampling2D(size=(2, 2))(dec)# 长宽加倍\n",
    "    # (64,64)\n",
    "    dec = Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu')(dec)\n",
    "    dec = BatchNormalization()(dec)\n",
    "    dec = Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu')(dec)\n",
    "    dec = BatchNormalization()(dec)\n",
    "    dec = Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu')(dec)\n",
    "    dec = BatchNormalization()(dec)\n",
    "    dec = UpSampling2D(size=(2, 2))(dec)# 长宽加倍\n",
    "    # (128,128)\n",
    "    dec = Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu')(dec)\n",
    "    dec = BatchNormalization()(dec)\n",
    "    dec = Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu')(dec)\n",
    "    dec = BatchNormalization()(dec)\n",
    "    dec = UpSampling2D(size=(2, 2))(dec)# 长宽加倍\n",
    "    # (256,256)\n",
    "    # 最终输出层\n",
    "    dec = Conv2D(64, (3, 3), strides=(1, 1), input_shape=input_shape, padding='same', activation='relu')(dec)\n",
    "    dec = BatchNormalization()(dec)\n",
    "    dec = Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu')(dec)\n",
    "    dec = BatchNormalization()(dec)\n",
    "    dec = Conv2D(out_channel, (1, 1), strides=(1, 1), padding='same')(dec)\n",
    "    # 形状调整层\n",
    "    #dec = Reshape((1, img_width * img_height))(dec)\n",
    "    #dec = Permute((2, 1))(dec)# axis=1和axis=2互换位置，等同于np.swapaxes(layer,1,2)\n",
    "    #dec = Reshape((img_width , img_height, 1))(dec)\n",
    "    outp_1 = Activation('softmax', name='5_split_Output')(dec)\n",
    "\n",
    "    #分类分支\n",
    "    outp_2 = Flatten()(enc)\n",
    "    outp_2 = Dense(256, activation='relu')(outp_2)\n",
    "    outp_2 = Dense(5, activation='softmax', name='5_Category_Output')(outp_2)\n",
    "\n",
    "    model = Model(inp,\n",
    "                  [outp_1, outp_2])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8efbd78f-48e3-41c2-b751-43f101d7dfa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef dynamic_mean_iou(y_true, y_pred, num_classes=out_channel):\\n    prec = []\\n    for t in np.arange(0.5, 1.0, 0.05):\\n        # 多分类阈值处理\\n        y_pred_class = tf.cast(y_pred > t, tf.int32)\\n        y_pred_flat = tf.reshape(y_pred_class, [-1, num_classes])\\n        y_true_flat = tf.one_hot(tf.reshape(y_true, [-1]), depth=num_classes)\\n        \\n        # 动态IoU计算\\n        intersection = tf.reduce_sum(y_true_flat * y_pred_flat, axis=0)\\n        union = tf.reduce_sum(y_true_flat, axis=0) + tf.reduce_sum(y_pred_flat, axis=0) - intersection\\n        iou = (intersection + 1e-7) / (union + 1e-7)  # 1e-7防除零\\n        \\n        prec.append(tf.reduce_mean(iou))  # 各阈值mIoU\\n    \\n    return K.mean(K.stack(prec), axis=0)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 多阈值平均IoU\n",
    "\"\"\"\n",
    "单阈值（如0.5）仅反映模型在某一特定定位精度下的表现\n",
    "而多阈值通过覆盖宽范围的IoU值（如0.5到0.95，步长0.05），综合评估模型在不同定位精度要求下的稳定性\n",
    "多阈值设计确实能有效避免预测结果处于模糊的中间态\n",
    "多阈值IoU常用于目标检测（如COCO的IoU@[0.5:0.95]）以评估定位鲁棒性，但语义分割的评估更侧重类别区分而非几何重叠精度\n",
    "多阈值需存储多个二值化掩膜，如10个阈值将显存占用提升10倍\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "def dynamic_mean_iou(y_true, y_pred, num_classes=out_channel):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        # 多分类阈值处理\n",
    "        y_pred_class = tf.cast(y_pred > t, tf.int32)\n",
    "        y_pred_flat = tf.reshape(y_pred_class, [-1, num_classes])\n",
    "        y_true_flat = tf.one_hot(tf.reshape(y_true, [-1]), depth=num_classes)\n",
    "        \n",
    "        # 动态IoU计算\n",
    "        intersection = tf.reduce_sum(y_true_flat * y_pred_flat, axis=0)\n",
    "        union = tf.reduce_sum(y_true_flat, axis=0) + tf.reduce_sum(y_pred_flat, axis=0) - intersection\n",
    "        iou = (intersection + 1e-7) / (union + 1e-7)  # 1e-7防除零\n",
    "        \n",
    "        prec.append(tf.reduce_mean(iou))  # 各阈值mIoU\n",
    "    \n",
    "    return K.mean(K.stack(prec), axis=0)\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28475e2b-2bcc-4285-bf9e-58998b908f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "def dice_coef(y_true, y_pred):\n",
    "    \"\"\"Dice系数，用于评估分割性能\"\"\"\n",
    "    smooth = 1.\n",
    "    y_true_f = K.cast(K.flatten(y_true),dtype = 'float32')\n",
    "    y_pred_f = K.cast(K.flatten(y_pred),dtype = 'float32')\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    \"\"\"组合损失函数：交叉熵 + Dice损失\"\"\"\n",
    "    return 0.5 * keras.losses.binary_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)\n",
    "def bce_dice_loss_2(y_true, y_pred):\n",
    "    \n",
    "    return keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "def bce_dice_loss_3(y_true, y_pred):\n",
    "    \"\"\"纯交叉熵损失（用于分类任务）\"\"\"\n",
    "    return keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "344b9c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件不存在\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 256, 256, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 36928       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 256, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 128 512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 128 147584      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 128 512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 256)  1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  590080      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 256)  1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 256)  590080      batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 512)  2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 512)  2359808     batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 512)  2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 512)  2359808     batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 512)  2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 512)  2359808     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 512)  2048        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 512)  2359808     batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 512)  2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 512)  2359808     batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 512)  2048        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 512)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 16, 16, 512)  0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 512)  2359808     up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 512)  2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 512)  2359808     batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 512)  2359808     batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 512)  2048        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 512)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 512)  2359808     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 512)  2048        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 512)  2359808     batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 512)  2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 512)  2359808     batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 512)  2048        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 512)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 256)  1179904     up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64, 64, 256)  1024        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 256)  590080      batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 64, 64, 256)  1024        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 256)  590080      batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 64, 64, 256)  1024        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 256 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 128, 128, 128 295040      up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 128, 128, 128 512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 128, 128, 128 147584      batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 128, 128, 128 512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 256, 256, 128 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 256, 256, 64) 73792       up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 256, 256, 64) 256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 256, 256, 64) 36928       batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 256, 256, 64) 256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 32768)        0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 256, 256, 5)  325         batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          8388864     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "5_split_Output (Activation)     (None, 256, 256, 5)  0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "5_Category_Output (Dense)       (None, 5)            1285        dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 40,211,210\n",
      "Trainable params: 40,194,314\n",
      "Non-trainable params: 16,896\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#设置模型编译参数\n",
    "optimizer = 'rmsprop'\n",
    "loss =  {'5_split_Output': bce_dice_loss, # 分割任务损失\n",
    "         '5_Category_Output': bce_dice_loss_3# 分类任务损失\n",
    "        }\n",
    "loss_weights = [5.,1.]# 损失权重（分割:分类 = 5:1）\n",
    "metrics = {'5_split_Output': keras.metrics.MeanIoU(num_classes=2), # 分割IoU\n",
    "           '5_Category_Output': 'accuracy'# 分类准确率\n",
    "          }\n",
    "\n",
    "# 编译模型\n",
    "model= keras_model(img_width=img_width, img_height=img_height, out_channel=out_channel)\n",
    "model.compile(optimizer=optimizer, loss=loss, loss_weights =loss_weights, metrics=metrics)\n",
    "\n",
    "#加载预训练权重（如果有的话）\n",
    "\n",
    "if os.path.isfile(os.path.join(aug55Dir, weiPre)):  # os.path.isfile():检查文件是否存在，存在返回true\n",
    "    try:\n",
    "        model.load_weights(PretTrWei_path)# 加载预训练权重\n",
    "        print(\"预训练权重加载成功\")\n",
    "    except:\n",
    "        print(\"预训练权重加载失败\")\n",
    "else:\n",
    "    print(\"文件不存在\")\n",
    "\n",
    "# 展示模型结构\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9318f276",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "定义函数：数据生成器get_train_val_augmented\n",
    "输入：(validation_split, batch_size, seed)\n",
    "输出2个生成器：train_generator, val_generator\n",
    "topDir/\n",
    "└── working/\n",
    "    ├── stage1_train/\n",
    "    │   ├── images/        # 训练图像\n",
    "    │   └── segmentations/ # 训练分割标签\n",
    "    └── stage1_val/\n",
    "        ├── images/        # 测试图像\n",
    "        └── segmentations/ # 测试分割标签\n",
    "\"\"\"\n",
    "\n",
    "def get_train_val_augmented(imgDir=imgDir, validation_split=0.3, batch_size=16, seed=seed, out_channel=out_channel):\n",
    "    \"\"\"\n",
    "    数据生成器功能：\n",
    "    1. 实时数据增强\n",
    "    2. 分割和分类标签的同步生成\n",
    "    \"\"\"\n",
    "    n_label = 1\n",
    "    \n",
    "    # 数据路径配置\n",
    "\n",
    "    X_train_path = os.path.join(imgDir, \"stage1_train\", \"images\")# 训练图像路径\n",
    "    Y_train_path = os.path.join(imgDir, \"stage1_train\", \"segmentations\")# 训练分割标签路径\n",
    "    X_val_path = os.path.join(imgDir, \"stage1_val\", \"images\")# 测试图像路径\n",
    "    Y_val_path = os.path.join(imgDir, \"stage1_val\", \"segmentations\")# 测试分割标签路径\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    数据增强参数配置\n",
    "    定义字典data_gen_args和data_gen_args_2，用于配置增强参数。\n",
    "    \"\"\"\n",
    "    data_gen_args = dict(rotation_range=45,# 训练时图像会以中心为轴，在[-45°, 45°]范围内随机旋转，增加模型对物体方向变化的鲁棒性\n",
    "                         width_shift_range=0.1,# 图像宽度 ±10% 的随机垂直平移\n",
    "                         height_shift_range=0.1,# 图像高度 ±10% 的随机垂直平移\n",
    "                         shear_range=0.2,# 沿水平或垂直方向随机施加 ±0.2 弧度 的倾斜变形，模拟视角变化\n",
    "                         zoom_range=0.2,# 在 [0.8, 1.2] 倍区间内随机缩放图像\n",
    "                         horizontal_flip=True,# 以 50% 概率水平翻转图像\n",
    "                         vertical_flip=True,# 以 50% 概率垂直翻转图像\n",
    "                         fill_mode='reflect') # reflect 表示用图像边缘像素的反射值填充空白，避免出现黑色或纯色边界\n",
    "    \n",
    "    data_gen_args_2 = dict(width_shift_range=0.1,# 图像宽度 ±10% 的随机垂直平移\n",
    "                         height_shift_range=0.1,# 图像高度 ±10% 的随机垂直平移\n",
    "                         horizontal_flip=True,# 以 50% 概率水平翻转图像\n",
    "                         vertical_flip=True,# 以 50% 概率垂直翻转图像\n",
    "                         fill_mode='reflect') # reflect 表示用图像边缘像素的反射值填充空白，避免出现黑色或纯色边界\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    训练数据生成器\n",
    "    ImageDataGenerator 是 Keras 库中的一个类，属于深度学习框架中用于图像数据增强的核心工具\n",
    "    利用字典data_gen_args实例化类ImageDataGenerator，从而获得实例X_datagen用于生成\n",
    "    \n",
    "    \"\"\"\n",
    "    X_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    Y_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    \n",
    "    #channels = K.image_data_format()\n",
    "    \n",
    "    \"\"\"\n",
    "    定义数据生成器（函数）train_generator\n",
    "    输入(seed, X_datagen, Y_datagen, Y_train_path, X_train_path )\n",
    "    不断的输出张量数组\n",
    "    当函数中首次遇到 yield 时，函数会 暂停执行，并将 yield 后的值返回给调用者。\n",
    "    此时，函数的状态（包括局部变量、指令指针等）会被完整保留。\n",
    "    当生成器被调用 next()再次激活，函数会从上次暂停的位置 恢复执行，直到遇到下一个 yield 或函数结束。\n",
    "    while True 循环使生成器 无限循环执行，每次循环都会通过 yield 返回一个新的批次数据 X_traini, [Y_traini, C_traini]\n",
    "    这种设计使得生成器可以持续输出数据，而无需一次性加载全部数据到内存，从而节省内存\n",
    "    \"\"\"\n",
    "    \n",
    "    def train_generator(seed=seed, X_datagen=X_datagen, Y_datagen=Y_datagen, Y_train_path=Y_train_path, X_train_path = X_train_path):\n",
    "        \"\"\"\n",
    "        训练数据生成流程\n",
    "        X_datagen 是 ImageDataGenerator 的实例\n",
    "        flow_from_directory() 是 ImageDataGenerator 类的一个方法，\n",
    "        用于从指定目录加载图像数据并生成增强后的数据流。调用该方法时，返回的是一个 生成器对象（DirectoryIterator 类的实例）。\n",
    "        变量X_train_augmented 获得生成器对象的赋值\n",
    "        \"\"\"\n",
    "        # 图像流\n",
    "        X_train_augmented = X_datagen.flow_from_directory(X_train_path,  # 根目录下需按类别划分子文件夹，每个子文件夹内的图像自动归类为对应类别\n",
    "                                                          target_size=(img_height, img_width), #将所有图像统一缩放到指定尺寸\n",
    "                                                          class_mode=None,#不生成标签数据\n",
    "                                                          color_mode=\"rgb\", #将图像转换为 RGB 三通道格式\n",
    "                                                          batch_size=batch_size, #定义每个批次的样本数量\n",
    "                                                          shuffle=True,#打乱数据顺序，防止模型因数据排列产生偏差\n",
    "                                                          seed=seed#固定随机种子，确保每次运行时数据增强和打乱顺序的一致性（便于复现实验）\n",
    "                                                         )\n",
    "        # 标签流\n",
    "        Y_train_augmented = Y_datagen.flow_from_directory(Y_train_path,  # 根目录下需按类别划分子文件夹，每个子文件夹内的图像自动归类为对应类别\n",
    "                                                          target_size=(img_height, img_width),\n",
    "                                                          class_mode=\"categorical\",#生成标签数据，返回 二维的 one-hot 编码标签，适合多分类任务\n",
    "                                                          color_mode=\"grayscale\", #确保单通道读取\n",
    "                                                          batch_size=batch_size, \n",
    "                                                          shuffle=True,\n",
    "                                                          seed=seed)\n",
    "        while True:\n",
    "            \"\"\"\n",
    "            X_datagen 和 Y_datagen 的 flow_from_directory() 使用相同的 seed 和 shuffle 参数，\n",
    "            确保输入图像和标签的增强操作（如旋转、翻转）完全一致，批次索引严格对应\n",
    "            \"\"\"\n",
    "            X_traini = X_train_augmented.next()\n",
    "            Y_traini1 = Y_train_augmented.next()\n",
    "            X_traini = np.array(X_traini, dtype=np.uint8)#将图像数据转换为 uint8（0-255像素值）比 float32 节省 75% 内存\n",
    "            Y_traini, C_traini = Y_traini1#标签分解：Y_traini1 包含多组标签（分割掩膜 Y_traini 和分类标签 C_traini）\n",
    "            Y_traini = np.array(Y_traini, dtype=np.bool_)# 标签转换为布尔值（二值掩膜）\n",
    "            \n",
    "            \n",
    "            C_traini_expanded = C_traini[:, np.newaxis, np.newaxis, :]\n",
    "            C_traini_expanded = np.array(C_traini_expanded, dtype=np.bool_)\n",
    "            Y_traini = Y_traini * C_traini_expanded\n",
    "            #result\n",
    "            Y_traini = np.array(Y_traini, dtype=np.float32)# 如无意外不用这条代码，Y_traini也是float32\n",
    "            #print(Y_traini.shape, Y_traini.dtype)\n",
    "            #print(C_traini.shape, C_traini.dtype)\n",
    "            #max_X = tf.reduce_max(X_traini)\n",
    "            #min_X = tf.reduce_min(X_traini)\n",
    "            #print(\"最大值:\", max_X.numpy(), \"最小值:\", min_X.numpy())\n",
    "\n",
    "            \n",
    "            #max_Y = tf.reduce_max(Y_traini)\n",
    "            #min_Y = tf.reduce_min(Y_traini)\n",
    "            #print(\"最大值:\", max_Y.numpy(), \"最小值:\", min_Y.numpy())\n",
    "            #print(C_traini)\n",
    "            \"\"\"\n",
    "            # 标签维度转换（网页7中的多通道需求）需要原图中以1234标明缺陷标签\n",
    "            Y_batch = tf.keras.utils.to_categorical(Y_batch, num_classes=out_channel)\n",
    "            Y_batch = Y_batch.reshape(-1, img_height, img_width, out_channel)\n",
    "            print(\"训练集标签范围:\", np.unique(Y_traini))\n",
    "            \n",
    "\n",
    "            \"\"\"\n",
    "            yield X_traini, [Y_traini, C_traini]#返回 [Y_traini, C_traini]，可同时处理多任务学习\n",
    "\n",
    "    # 验证数据生成器（不进行数据增强）\n",
    "    X_datagen_val = ImageDataGenerator()\n",
    "    Y_datagen_val = ImageDataGenerator()\n",
    "\n",
    "    def val_generator(seed=seed, X_datagen_val=X_datagen_val, Y_datagen_val=Y_datagen_val, Y_val_path=Y_val_path, X_val_path = X_val_path):\n",
    "        \"\"\"验证数据生成流程\"\"\"\n",
    "        # 图像流\n",
    "        X_val_augmented = X_datagen_val.flow_from_directory(X_val_path, \n",
    "                                                             target_size=(img_height, img_width), class_mode=None,\n",
    "                                                             color_mode=\"rgb\", batch_size=batch_size, shuffle=True, seed=seed)\n",
    "        # 标签流\n",
    "        Y_val_augmented = Y_datagen_val.flow_from_directory(Y_val_path, \n",
    "                                                             target_size=(img_height, img_width),class_mode=\"categorical\",#生成标签数据\n",
    "                                                             color_mode=\"grayscale\", batch_size=batch_size, shuffle=True,\n",
    "                                                             seed=seed)\n",
    "        while True:\n",
    "            X_vali = X_val_augmented.next()\n",
    "            Y_vali1 = Y_val_augmented.next()\n",
    "            X_vali = np.array(X_vali, dtype=np.uint8)\n",
    "            Y_vali, C_vali = Y_vali1\n",
    "            Y_vali = np.array(Y_vali, dtype=np.bool_)\n",
    "            \n",
    "            C_vali_expanded = C_vali[:, np.newaxis, np.newaxis, :]\n",
    "            C_vali_expanded = np.array(C_vali_expanded, dtype=np.bool_)\n",
    "            Y_vali = Y_vali * C_vali_expanded\n",
    "            #result\n",
    "            Y_vali = np.array(Y_vali, dtype=np.float32)# 如无意外不用这条代码，Y_vali也是float32\n",
    "            yield X_vali, [Y_vali, C_vali]\n",
    "\n",
    "    \n",
    "    # combine generators into one which yields image and masks\n",
    "    train_generator = train_generator(seed=seed, X_datagen=X_datagen, Y_datagen=Y_datagen, Y_train_path=Y_train_path, X_train_path = X_train_path)\n",
    "    val_generator = val_generator(seed=seed, X_datagen_val=X_datagen_val, Y_datagen_val=Y_datagen_val, Y_val_path=Y_val_path, X_val_path = X_val_path)\n",
    "\n",
    "    return train_generator, val_generator #输出2个生成器\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "233e596d-2b1b-4017-97df-7649142ae26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "定义函数translate_metric\n",
    "其作用是将机器学习或数据分析中常用的缩写指标名称（如 'acc' 或 'loss'）转换为全称，用以作为标题输出\n",
    "旧版Keras（如 <2.3.0）与新版本TensorFlow（≥2.4.0）的API差异可能导致指标名称注册失败：\n",
    "旧版使用 acc 作为准确率名称，新版统一为 accuracy\n",
    "\"\"\"\n",
    "def translate_metric(x):\n",
    "    translations = {'acc': \"Accuracy\", \n",
    "                    'accuracy': \"Accuracy\", \n",
    "                    'loss': \"Log-loss (cost function)\"}\n",
    "    if x in translations:\n",
    "        return translations[x]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#from tensorflow.keras.callbacks import Callback\n",
    "#from IPython.display import clear_output\n",
    "\"\"\"\n",
    "自定义一个的Keras回调函数PlotLosses，用于在模型训练过程中实时动态绘制训练集和验证集的指标变化曲线\n",
    "在每轮（epoch）训练结束后，自动绘制训练集和验证集的损失（loss）或准确率（accuracy）等指标的动态变化曲线，\n",
    "通过图表直观展示模型收敛情况\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class PlotLosses(Callback):#创建新类PlotLosses继承自基类Callback\n",
    "    \"\"\"\n",
    "    在子类中重新定义了初始化方法，这个方法要求在创建实例时需要哪些输入：figsize\n",
    "    \"\"\"\n",
    "    def __init__(self, figsize=None):\n",
    "        #super(PlotLosses, self).__init__()#兼容 Python 2\n",
    "        super().__init__()#Python 3+ 特有\n",
    "        \"\"\"\n",
    "        1.super().__init__() 的作用是 调用父类的 __init__ 方法以初始化继承自父类的属性\n",
    "\n",
    "        2.每个父类的__init__()方法旨在初始化 该类的特有属性 。例如：\n",
    "        Character类初始化角色名、生命值等；\n",
    "        People类初始化姓名、年龄、性别等通用属性\n",
    "        3.当子类 未重写 __init__() 方法时，父类的 __init__() 会被自动继承。\n",
    "        此时子类实例化时，会直接执行父类的初始化逻辑\n",
    "        4.如果子类 重写了 __init__() 方法，则父类的 __init__() 会被覆盖，\n",
    "        子类的初始化逻辑完全由自身定义。此时父类的 __init__() 不会自动执行，除非通过 super() 显式调用\n",
    "        这里是重新定义了__init__()方法，所以要用该代码显式调用\n",
    "        5.继承是静态的：通过类定义实现，父类方法默认存在于子类中\n",
    "        6.调用是动态的：通过 super() 决定是否触发父类的初始化逻辑\n",
    "        7.子类重写 __init__ 后：父类的 __init__ 仍存在，但需显式调用才能执行\n",
    "        8.__init__() 是唯一在实例化时由 Python 自动调用的方法，\n",
    "        这是一个软约束，正是这个功能使得__init__()被称为初始化\n",
    "        即使未定义，Python 也会隐式调用父类的 __init__()（若存在）\n",
    "        9.Python 要求 __init__() 必须返回 None，不能显式返回其他值。这是其与普通方法的重要区别\n",
    "        这是一个硬约束\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        参数figsize：控制图表大小，例如(16,4)表示宽16英寸、高4英寸\n",
    "        \"\"\"\n",
    "        self.figsize = figsize#给类的实例定义了一个属性：figsize\n",
    "\n",
    "    \"\"\"\n",
    "    定义了类的1个方法\n",
    "    对于类的方法，最常用的触发方式就是通过实例直接调用：实例.方法\n",
    "    在 Keras 训练流程中，keras会在某些节点触发回调函数的on_train_begin 和 on_epoch_end 方法\n",
    "    \n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        \"\"\"\n",
    "        定义2个属性base_metrics，logs\n",
    "        核心意义\n",
    "\n",
    "        在 Keras 中，如果在模型编译时设置了 metrics 参数（如 accuracy），则：\n",
    "        训练阶段的指标名称：直接使用定义时的名称（如 loss, accuracy）。\n",
    "        验证阶段的指标名称：自动添加 val_ 前缀（如 val_loss, val_accuracy）。\n",
    "\n",
    "        通过过滤掉以 val_ 开头的指标，\n",
    "        仅保留训练阶段的评估指标，方便后续对训练结果的分析（如绘制训练曲线、记录性能日志等）\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        在on_train_begin时self.model.metrics_names经常是空的\n",
    "        所以，不如在on_epoch_end再建立self.base_metrics\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"self.model.metrics_names:\", self.model.metrics_names)\n",
    "        \"\"\"\n",
    "        1.\n",
    "        self.model 是父类 Callback 提供的属性，指向当前训练或评估的模型实例\n",
    "        当回调函数被绑定到模型时，Keras框架会通过 set_model() 方法将模型实例赋给 self.model\n",
    "        这意味着 self.model 是 Callback 类为子类提供的一个接口，用于访问当前操作的模型\n",
    "        2.\n",
    "        metrics_names 是 模型实例的属性\n",
    "        当调用 model.compile(metrics=[...]) 时，\n",
    "        Keras 会根据 loss 和 metrics 参数生成 metrics_names 列表\n",
    "        验证集指标会以 val_ 前缀命名（如 val_loss、val_accuracy）\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.base_metrics = [metric #筛选后的指标名称存入 self.base_metrics 列表\n",
    "                             for metric #2个metric是一回事，作为一个工具，指代self.model.metrics_names中符合删选条件的元素\n",
    "                             in self.model.metrics_names #继承自父类：模型的所有评估指标名称列表\n",
    "                             if not metric.startswith('val_')#排除以 val_ 开头的指标\n",
    "                            ]\n",
    "        #self.base_metrics = [metric for metric in self.params['metrics'] if not metric.startswith('val_')]\n",
    "        \n",
    "        print(\"self.base_metrics:\", self.base_metrics)\n",
    "        \"\"\"\n",
    "        self.logs = []#logs要在on_train_begin触发时初始化用以存放之后产生的训练log\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.base_metrics = [metric #筛选后的指标名称存入 self.base_metrics 列表\n",
    "                             for metric #2个metric是一回事，作为一个工具，指代self.model.metrics_names中符合删选条件的元素\n",
    "                             in self.model.metrics_names #继承自父类：模型的所有评估指标名称列表\n",
    "                             if not metric.startswith('val_')#排除以 val_ 开头的指标\n",
    "                            ]\n",
    "        #self.base_metrics = [metric for metric in self.params['metrics'] if not metric.startswith('val_')]\n",
    "        print(\"self.base_metrics:\", self.base_metrics)\n",
    "        self.logs.append(logs.copy())# 记录当前epoch的指标值\n",
    "        \"\"\"\n",
    "        使用clear_output(wait=True)清除旧图表并重新绘制，实现在同一位置刷新图像（适用于Jupyter Notebook等交互环境）\n",
    "        \"\"\"\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=self.figsize)# 初始化画布\n",
    "\n",
    "        for metric_id, metric in enumerate(self.base_metrics):\n",
    "            plt.subplot(1, len(self.base_metrics), metric_id + 1)\n",
    "\n",
    "            plt.plot(range(1, len(self.logs) + 1),\n",
    "                     [log[metric] for log in self.logs],\n",
    "                     label=\"training\")\n",
    "            #if self.params['do_validation']:\n",
    "            \"\"\"\n",
    "            self.params['do_validation'] 是一个布尔值参数，用于指示模型在训练时是否执行验证步骤。其值由以下条件决定：\n",
    "            若在 model.fit() 中显式传入 validation_data 或设置 validation_split，则值为 True；\n",
    "            若未提供任何验证数据，则值为 False。\n",
    "            \"\"\"\n",
    "            has_validation = any(key.startswith('val_') for key in logs.keys())\n",
    "            if has_validation:\n",
    "                plt.plot(range(1, len(self.logs) + 1),\n",
    "                         [log['val_' + metric] for log in self.logs],\n",
    "                         label=\"validation\")\n",
    "            #plt.title(translate_metric(metric))\n",
    "            #plt.title(metric.capitalize())  # 标题优化（替代translate_metric）\n",
    "            plt.xlabel('epoch')#\n",
    "            plt.legend(loc='center left')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show();#展示图表\n",
    "        #plt.pause(0.1)  # 允许图像更新\n",
    "\n",
    "plot_losses = PlotLosses(figsize=(16, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28b15d4-90c3-4286-9a4f-99df4b2eeebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bb28c60-0e19-4c0d-ac6c-67ea818f745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练配置\n",
    "callbacks_list = [\n",
    "    plot_losses,# 可视化回调\n",
    "    # 模型动态保存\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = os.path.join(aug55Dir, weiDur),\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    # 动态学习率调整\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1, patience=10\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "617c54bc-a423-427a-b8b9-55807a748198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m\n\u001b[0;32m     12\u001b[0m train_generator, val_generator \u001b[38;5;241m=\u001b[39m get_train_val_augmented(imgDir\u001b[38;5;241m=\u001b[39mimgDir, validation_split\u001b[38;5;241m=\u001b[39mvalidation_split, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#len(X_train1)/(batch_size*2),\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#len(C_val1)/epochs,\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mplot_losses\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m           \u001b[38;5;66;03m#callbacks=callbacks_list)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# 保存最终模型为hdf5文件\u001b[39;00m\n\u001b[0;32m     23\u001b[0m model_out \u001b[38;5;241m=\u001b[39m model\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:108\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_multi_worker_mode():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m   \u001b[38;5;66;03m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dc_context\u001b[38;5;241m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1137\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1134\u001b[0m   val_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m   1135\u001b[0m   epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n\u001b[1;32m-> 1137\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_logs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1138\u001b[0m training_logs \u001b[38;5;241m=\u001b[39m epoch_logs\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py:416\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_logs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Only convert once.\u001b[39;00m\n\u001b[0;32m    415\u001b[0m   numpy_logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39mto_numpy_or_python_type(logs)\n\u001b[1;32m--> 416\u001b[0m \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumpy_logs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 145\u001b[0m, in \u001b[0;36mPlotLosses.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    142\u001b[0m     plt\u001b[38;5;241m.\u001b[39mlegend(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter left\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    144\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[1;32m--> 145\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\pyplot.py:446\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    445\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib_inline\\backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m figure_manager \u001b[38;5;129;01min\u001b[39;00m Gcf\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m---> 90\u001b[0m         \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fetch_figure_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     show\u001b[38;5;241m.\u001b[39m_to_draw \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\IPython\\core\\display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\IPython\\core\\formatters.py:179\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    177\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\IPython\\core\\formatters.py:223\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 223\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\IPython\\core\\formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    342\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\IPython\\core\\pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 152\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\backend_bases.py:2366\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2362\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2363\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[0;32m   2364\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[0;32m   2365\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m-> 2366\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2368\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2369\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2370\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2371\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2372\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2373\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\backend_bases.py:2232\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2228\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[0;32m   2229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2230\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m   2231\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[1;32m-> 2232\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2233\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:509\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 509\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:457\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[1;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_print_pil\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    453\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;124;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;124;03m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 457\u001b[0m     \u001b[43mFigureCanvasAgg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m     mpl\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave(\n\u001b[0;32m    459\u001b[0m         filename_or_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_rgba(), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mfmt, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    460\u001b[0m         dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi, metadata\u001b[38;5;241m=\u001b[39mmetadata, pil_kwargs\u001b[38;5;241m=\u001b[39mpil_kwargs)\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:400\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m RendererAgg\u001b[38;5;241m.\u001b[39mlock, \\\n\u001b[0;32m    398\u001b[0m      (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\u001b[38;5;241m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\n\u001b[0;32m    399\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdraw()\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[0;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\figure.py:3175\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3172\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   3174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 3175\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sfig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubfigs:\n\u001b[0;32m   3179\u001b[0m     sfig\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 131\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\axes\\_base.py:3064\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[0;32m   3062\u001b[0m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[1;32m-> 3064\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3067\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3068\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 131\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\legend.py:734\u001b[0m, in \u001b[0;36mLegend.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    731\u001b[0m     Shadow(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlegendPatch, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlegendPatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m--> 734\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_legend_box\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    736\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlegend\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\artist.py:39\u001b[0m, in \u001b[0;36m_prevent_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m     renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n\u001b[0;32m     37\u001b[0m     renderer\u001b[38;5;241m.\u001b[39m_rasterizing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\offsetbox.py:412\u001b[0m, in \u001b[0;36mOffsetBox.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw\u001b[39m(\u001b[38;5;28mself\u001b[39m, renderer):\n\u001b[0;32m    408\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;124;03m    Update the location of children if necessary and draw them\u001b[39;00m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;124;03m    to the given *renderer*.\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 412\u001b[0m     bbox, offsets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_bbox_and_child_offsets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    413\u001b[0m     px, py \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_offset(bbox, renderer)\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c, (ox, oy) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_visible_children(), offsets):\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\offsetbox.py:485\u001b[0m, in \u001b[0;36mVPacker._get_bbox_and_child_offsets\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(c, PackerBase) \u001b[38;5;129;01mand\u001b[39;00m c\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    483\u001b[0m             c\u001b[38;5;241m.\u001b[39mset_width(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth)\n\u001b[1;32m--> 485\u001b[0m bboxes \u001b[38;5;241m=\u001b[39m [c\u001b[38;5;241m.\u001b[39mget_bbox(renderer) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_visible_children()]\n\u001b[0;32m    486\u001b[0m (x0, x1), xoffsets \u001b[38;5;241m=\u001b[39m _get_aligned_offsets(\n\u001b[0;32m    487\u001b[0m     [bbox\u001b[38;5;241m.\u001b[39mintervalx \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m bboxes], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign)\n\u001b[0;32m    488\u001b[0m height, yoffsets \u001b[38;5;241m=\u001b[39m _get_packed_offsets(\n\u001b[0;32m    489\u001b[0m     [bbox\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m bboxes], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight, sep, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode)\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\offsetbox.py:485\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(c, PackerBase) \u001b[38;5;129;01mand\u001b[39;00m c\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    483\u001b[0m             c\u001b[38;5;241m.\u001b[39mset_width(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth)\n\u001b[1;32m--> 485\u001b[0m bboxes \u001b[38;5;241m=\u001b[39m [\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_visible_children()]\n\u001b[0;32m    486\u001b[0m (x0, x1), xoffsets \u001b[38;5;241m=\u001b[39m _get_aligned_offsets(\n\u001b[0;32m    487\u001b[0m     [bbox\u001b[38;5;241m.\u001b[39mintervalx \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m bboxes], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign)\n\u001b[0;32m    488\u001b[0m height, yoffsets \u001b[38;5;241m=\u001b[39m _get_packed_offsets(\n\u001b[0;32m    489\u001b[0m     [bbox\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m bboxes], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight, sep, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode)\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\offsetbox.py:367\u001b[0m, in \u001b[0;36mOffsetBox.get_bbox\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_bbox\u001b[39m(\u001b[38;5;28mself\u001b[39m, renderer):\n\u001b[0;32m    366\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the bbox of the offsetbox, ignoring parent offsets.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 367\u001b[0m     bbox, offsets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_bbox_and_child_offsets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bbox\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\offsetbox.py:512\u001b[0m, in \u001b[0;36mHPacker._get_bbox_and_child_offsets\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    509\u001b[0m pad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad \u001b[38;5;241m*\u001b[39m dpicor\n\u001b[0;32m    510\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msep \u001b[38;5;241m*\u001b[39m dpicor\n\u001b[1;32m--> 512\u001b[0m bboxes \u001b[38;5;241m=\u001b[39m [c\u001b[38;5;241m.\u001b[39mget_bbox(renderer) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_visible_children()]\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m bboxes:\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Bbox\u001b[38;5;241m.\u001b[39mfrom_bounds(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mpadded(pad), []\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\offsetbox.py:512\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    509\u001b[0m pad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad \u001b[38;5;241m*\u001b[39m dpicor\n\u001b[0;32m    510\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msep \u001b[38;5;241m*\u001b[39m dpicor\n\u001b[1;32m--> 512\u001b[0m bboxes \u001b[38;5;241m=\u001b[39m [\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_visible_children()]\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m bboxes:\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Bbox\u001b[38;5;241m.\u001b[39mfrom_bounds(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mpadded(pad), []\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\offsetbox.py:367\u001b[0m, in \u001b[0;36mOffsetBox.get_bbox\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_bbox\u001b[39m(\u001b[38;5;28mself\u001b[39m, renderer):\n\u001b[0;32m    366\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the bbox of the offsetbox, ignoring parent offsets.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 367\u001b[0m     bbox, offsets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_bbox_and_child_offsets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bbox\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\offsetbox.py:485\u001b[0m, in \u001b[0;36mVPacker._get_bbox_and_child_offsets\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(c, PackerBase) \u001b[38;5;129;01mand\u001b[39;00m c\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    483\u001b[0m             c\u001b[38;5;241m.\u001b[39mset_width(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth)\n\u001b[1;32m--> 485\u001b[0m bboxes \u001b[38;5;241m=\u001b[39m [c\u001b[38;5;241m.\u001b[39mget_bbox(renderer) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_visible_children()]\n\u001b[0;32m    486\u001b[0m (x0, x1), xoffsets \u001b[38;5;241m=\u001b[39m _get_aligned_offsets(\n\u001b[0;32m    487\u001b[0m     [bbox\u001b[38;5;241m.\u001b[39mintervalx \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m bboxes], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign)\n\u001b[0;32m    488\u001b[0m height, yoffsets \u001b[38;5;241m=\u001b[39m _get_packed_offsets(\n\u001b[0;32m    489\u001b[0m     [bbox\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m bboxes], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight, sep, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode)\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\offsetbox.py:485\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(c, PackerBase) \u001b[38;5;129;01mand\u001b[39;00m c\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    483\u001b[0m             c\u001b[38;5;241m.\u001b[39mset_width(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth)\n\u001b[1;32m--> 485\u001b[0m bboxes \u001b[38;5;241m=\u001b[39m [\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_visible_children()]\n\u001b[0;32m    486\u001b[0m (x0, x1), xoffsets \u001b[38;5;241m=\u001b[39m _get_aligned_offsets(\n\u001b[0;32m    487\u001b[0m     [bbox\u001b[38;5;241m.\u001b[39mintervalx \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m bboxes], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign)\n\u001b[0;32m    488\u001b[0m height, yoffsets \u001b[38;5;241m=\u001b[39m _get_packed_offsets(\n\u001b[0;32m    489\u001b[0m     [bbox\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m bboxes], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight, sep, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode)\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\offsetbox.py:367\u001b[0m, in \u001b[0;36mOffsetBox.get_bbox\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_bbox\u001b[39m(\u001b[38;5;28mself\u001b[39m, renderer):\n\u001b[0;32m    366\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the bbox of the offsetbox, ignoring parent offsets.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 367\u001b[0m     bbox, offsets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_bbox_and_child_offsets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bbox\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\offsetbox.py:512\u001b[0m, in \u001b[0;36mHPacker._get_bbox_and_child_offsets\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    509\u001b[0m pad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad \u001b[38;5;241m*\u001b[39m dpicor\n\u001b[0;32m    510\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msep \u001b[38;5;241m*\u001b[39m dpicor\n\u001b[1;32m--> 512\u001b[0m bboxes \u001b[38;5;241m=\u001b[39m [c\u001b[38;5;241m.\u001b[39mget_bbox(renderer) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_visible_children()]\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m bboxes:\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Bbox\u001b[38;5;241m.\u001b[39mfrom_bounds(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mpadded(pad), []\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\offsetbox.py:512\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    509\u001b[0m pad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad \u001b[38;5;241m*\u001b[39m dpicor\n\u001b[0;32m    510\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msep \u001b[38;5;241m*\u001b[39m dpicor\n\u001b[1;32m--> 512\u001b[0m bboxes \u001b[38;5;241m=\u001b[39m [\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_visible_children()]\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m bboxes:\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Bbox\u001b[38;5;241m.\u001b[39mfrom_bounds(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mpadded(pad), []\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\offsetbox.py:670\u001b[0m, in \u001b[0;36mDrawingArea.get_bbox\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_bbox\u001b[39m(\u001b[38;5;28mself\u001b[39m, renderer):\n\u001b[0;32m    668\u001b[0m     \u001b[38;5;66;03m# docstring inherited\u001b[39;00m\n\u001b[0;32m    669\u001b[0m     dpi_cor \u001b[38;5;241m=\u001b[39m renderer\u001b[38;5;241m.\u001b[39mpoints_to_pixels(\u001b[38;5;241m1.\u001b[39m)\n\u001b[1;32m--> 670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_bounds\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxdescent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdpi_cor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mydescent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdpi_cor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdpi_cor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdpi_cor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\transforms.py:807\u001b[0m, in \u001b[0;36mBbox.from_bounds\u001b[1;34m(x0, y0, width, height)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_bounds\u001b[39m(x0, y0, width, height):\n\u001b[0;32m    802\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;124;03m    Create a new `Bbox` from *x0*, *y0*, *width* and *height*.\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \n\u001b[0;32m    805\u001b[0m \u001b[38;5;124;03m    *width* and *height* may be negative.\u001b[39;00m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_extents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\transforms.py:826\u001b[0m, in \u001b[0;36mBbox.from_extents\u001b[1;34m(minpos, *args)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_extents\u001b[39m(\u001b[38;5;241m*\u001b[39margs, minpos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    811\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03m    Create a new Bbox from *left*, *bottom*, *right* and *top*.\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;124;03m       scales where negative bounds result in floating point errors.\u001b[39;00m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 826\u001b[0m     bbox \u001b[38;5;241m=\u001b[39m \u001b[43mBbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m minpos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m         bbox\u001b[38;5;241m.\u001b[39m_minpos[:] \u001b[38;5;241m=\u001b[39m minpos\n",
      "File \u001b[1;32mC:\\software\\Anaconda3\\envs\\py38GP\\lib\\site-packages\\matplotlib\\transforms.py:772\u001b[0m, in \u001b[0;36mBbox.__init__\u001b[1;34m(self, points, **kwargs)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;66;03m# it is helpful in some contexts to know if the bbox is a\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;66;03m# default or has been mutated; we store the orig points to\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;66;03m# support the mutated methods\u001b[39;00m\n\u001b[1;32m--> 772\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_points_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_points\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 启动训练\n",
    "batch_size = 2\n",
    "# 批大小：每次迭代（iteration）输入到模型中的样本数量。每个batch后更新模型参数\n",
    "#小批量（如32）引入随机性，可能帮助模型跳出局部最小值；大批量（如1024）提高计算效率但可能降低泛化能力\n",
    "#显存不足时需减小batch_size\n",
    "epochs=100\n",
    "# 轮次：整个训练数据集被完整遍历一次的次数。每个epoch结束后评估模型表现\n",
    "# 过少（如10）可能导致欠拟合，过多（如1000）易导致过拟合\n",
    "callbacks = callbacks_list\n",
    "validation_split=0.3\n",
    "\n",
    "train_generator, val_generator = get_train_val_augmented(imgDir=imgDir, validation_split=validation_split, batch_size=batch_size, seed=seed)\n",
    "\n",
    "model.fit(x=train_generator,\n",
    "                    validation_data=val_generator,\n",
    "                    steps_per_epoch=1,#len(X_train1)/(batch_size*2),\n",
    "                    validation_steps=1,#len(C_val1)/epochs,\n",
    "                    epochs=epochs,verbose=0,\n",
    "          callbacks=[plot_losses])\n",
    "          #callbacks=callbacks_list)\n",
    "\n",
    "# 保存最终模型为hdf5文件\n",
    "model_out = model\n",
    "model_out.save_weights(filepath=os.path.join(aug55Dir, weiEnd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c198b46c-f687-471b-a9de-4ed4e25cc356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38GP",
   "language": "python",
   "name": "py38gp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
